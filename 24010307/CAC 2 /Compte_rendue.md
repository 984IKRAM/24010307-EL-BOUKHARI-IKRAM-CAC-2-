# IKRAM ELBOUKHARI 
# CAC 2 
# 24010307
<img src="../../IMG_0641.png" height="464">
 
# üìò COMPTE RENDU DATA SCIENCE ‚Äî Python Learning & Exam Performance Dataset

# 1. Contexte M√©tier et Mission
A. Le Probl√®me (Business Case)
Dans l‚Äôenseignement num√©rique, les instructeurs manquent souvent d‚Äôoutils pour identifier :
quels √©tudiants risquent d‚Äô√©chouer,
quels comportements favorisent la r√©ussite,
quels facteurs influencent le score final.
  
  Objectif m√©tier :
Construire un mod√®le de Machine Learning capable :
1.de pr√©dire le score final d‚Äôun √©tudiant √† un examen Python,
2.d‚Äôidentifier les variables qui expliquent le mieux la r√©ussite,
3.d‚Äôaider √† construire une p√©dagogie personnalis√©e.

B. Le Dataset (Input)
Le dataset Python Learning & Exam Performance contient :
3000 √©tudiants
donn√©es d√©mographiques (√¢ge, pays)
donn√©es d‚Äôengagement p√©dagogique
donn√©es de performance
score final de l‚Äôexamen (0 √† 100)

La cible (y) est :
 final_exam_score

Les features (X) incluent :
heures d‚Äô√©tude, exercices r√©solus, projets r√©alis√©s, vid√©os regard√©es, etc.

# 2. Code Python (Laboratoire)

```python
# -----------------------------
# Pipeline complet ‚Äî RandomForestRegressor
# Dataset : Python Learning & Exam Performance
# -----------------------------

 0) Imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import warnings
warnings.filterwarnings("ignore")
sns.set_theme(style="whitegrid")
# 1) Chargement des donn√©es
df = pd.read_csv('/content/python_learning_exam_performance.csv')
print("Donn√©es charg√©es :", df.shape)
display(df.head())
# 2) Pr√©paration des donn√©es
TARGET = 'final_exam_score'
DROP_COLS = ['student_id', 'passed_exam']
X = df.drop(columns=DROP_COLS + [TARGET])
y = df[TARGET]

num_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()
cat_cols = X.select_dtypes(include=['object','category','bool']).columns.tolist()
# 3) Split Train/Test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.30, random_state=42
)
# 4) Pr√©processing
numeric_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))
])

preprocessor = ColumnTransformer([
    ('num', numeric_transformer, num_cols),
    ('cat', categorical_transformer, cat_cols)
])
# 5) Mod√®le Random Forest
rf = RandomForestRegressor(n_estimators=200, random_state=42)

pipeline = Pipeline([
    ('preproc', preprocessor),
    ('model', rf)
])
# 6) Entra√Ænement du mod√®le
pipeline.fit(X_train, y_train)
# 7) √âvaluation
y_pred = pipeline.predict(X_test)

r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("\n--- R√©sultats ---")
print(f"R¬≤ : {r2:.4f}")
print(f"MAE : {mae:.4f}")
print(f"RMSE : {rmse:.4f}")
# 8) Visualisation : Pr√©dictions vs R√©elles
plt.figure(figsize=(10,6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')
plt.xlabel('Valeurs R√©elles')
plt.ylabel('Pr√©dictions')
plt.title('Random Forest ‚Äî Pr√©dictions vs R√©elles')
plt.show()
# 9) Importance des variables
importances = pipeline.named_steps['model'].feature_importances_
```
# 3 . Nettoyage et Pr√©paration (Data Wrangling)

S√©paration des Caract√©ristiques (X) et de la Cible (y)
Proc√©dure : Le jeu de donn√©es a √©t√© s√©par√© en X (les caract√©ristiques/variables explicatives) et y (la variable cible, le score ou le statut de r√©ussite) avant toute imputation.

Justification : Cette √©tape est une bonne pratique cruciale pour pr√©venir le "data leakage" (fuite de donn√©es). Elle emp√™che que des informations contenues dans la cible (y) n'influencent par inadvertance
le processus de nettoyage des caract√©ristiques, pr√©servant ainsi l'int√©grit√© des donn√©es pour l'entra√Ænement du mod√®le.

Imputation avec SimpleImputer
Proc√©dure : Un transformateur SimpleImputer avec la strat√©gie 'mean' (moyenne) a √©t√© utilis√©. Cela signifie que pour chaque colonne num√©rique contenant des valeurs manquantes (NaN), 
ces entr√©es ont √©t√© remplac√©es par la moyenne des valeurs existantes de cette colonne.

Justification : Remplacer les valeurs manquantes par la moyenne est une strat√©gie courante lorsque la distribution des donn√©es est relativement normale et que le pourcentage de donn√©es manquantes est faible. 
Cela permet de ne pas perdre d'observations tout en pr√©servant l'ordre de grandeur des donn√©es.

Reconversion en DataFrame
Proc√©dure : Les donn√©es imput√©es ont √©t√© reconverties en un DataFrame Pandas (X_clean) pour conserver les noms des colonnes et faciliter les manipulations ult√©rieures.

Importance de l'√âtape
Finalit√© : Le nettoyage garantit que votre jeu de donn√©es est complet et utilisable par les mod√®les de Machine Learning, qui ne peuvent g√©n√©ralement pas traiter les valeurs manquantes.

Validation : Le processus confirme qu'apr√®s l'imputation, il reste 0 valeur manquante, ce qui signifie que l'ensemble de caract√©ristiques (X_clean) est propre et pr√™t pour la mod√©lisation.




# 5. Protocole Exp√©rimental (Train/Test Split)

Split utilis√© :
70% entra√Ænement (2100 √©tudiants)
30% test (900 √©tudiants)
Justification scientifique (comme dans Correction Projet.md) 
assez de donn√©es pour que le mod√®le apprenne des patterns,
suffisamment de donn√©es de test pour √©valuer la g√©n√©ralisation.

# 6  FOCUS TH√âORIQUE : Choix et Justification du Mod√®le (Mod√©lisation)

'ai utilis√© un d√©coupage 70/30 pour l'entra√Ænement/test.

Choix du Mod√®le (Random Forest Regressor) :

J'ai choisi le Random Forest car il est robuste et g√®re les relations non-lin√©aires complexes de mes donn√©es sans √™tre sensible √† l'overfitting.

Surtout, il me fournit l'Importance des Variables, ce qui est essentiel pour expliquer les facteurs de r√©ussite, allant au-del√† de la simple pr√©diction.

R√©sultats de la R√©gression :

R2 Score (Coefficient de D√©termination) : 0,5969
Interpr√©tation : Un score R2 d'environ 0,60 signifie que les caract√©ristiques (variables) incluses dans votre mod√®le expliquent environ 60 % de la variance (variabilit√©) du score d'examen final (final_exam_score).

Conclusion : Cela indique un ajustement mod√©r√©. Le mod√®le capture une part significative de la variabilit√© des scores, mais il reste une part substantielle (40 %) qui n'est pas expliqu√©e par les donn√©es utilis√©es.

Erreur Absolue Moyenne (Mean Absolute Error - MAE) : 8,8267
Interpr√©tation : En moyenne, les pr√©dictions du mod√®le pour le score d'examen final s'√©cartent du score r√©el d'environ 8,83 points.

Conclusion : Cette m√©trique est facilement interpr√©table et repr√©sente l'amplitude moyenne des erreurs de pr√©diction, sans tenir compte de leur direction (sur-estimation ou sous-estimation).

Racine de l'Erreur Quadratique Moyenne (Root Mean Squared Error - RMSE) : 11,0570
Interpr√©tation : La RMSE est d'environ 11,06 points.

Conclusion : Comme la MAE, elle mesure l'amplitude moyenne des erreurs, mais elle donne plus de poids aux erreurs plus importantes en raison de l'√©l√©vation au carr√©. Cette valeur est exprim√©e dans la m√™me unit√© que la variable cible (le score final), indiquant la taille typique des erreurs de pr√©diction.

Bien que le R2 sugg√®re un ajustement raisonnable, une erreur moyenne d'environ 9 √† 11 points peut √™tre consid√©r√©e comme mod√©r√©e si l'√©chelle des scores va de 0 √† 100. Le mod√®le est fonctionnel, mais il existe une marge d'am√©lioration significative pour r√©duire les erreurs de pr√©diction.

      2. Importance des Variables (Feature Importances)
L'importance des variables (g√©n√©r√©e par le Random Forest Regressor) indique les caract√©ristiques que le mod√®le a trouv√©es les plus influentes pour pr√©dire le score d'examen final.

Les caract√©ristiques typiquement importantes dans ce contexte √©ducatif sont :

hours_spent_learning_per_week (heures d'√©tude par semaine) : Intuitivement, plus de temps pass√© √† √©tudier devrait se traduire par des scores plus √©lev√©s.

practice_problems_solved (probl√®mes pratiques r√©solus) : Le nombre de probl√®mes compl√©t√©s est un indicateur fort de l'engagement et de la ma√Ætrise.

tutorial_videos_watched (vid√©os de tutoriel visionn√©es) : Refl√®te √©galement l'effort et l'engagement d'apprentissage.

self_reported_confidence_python (confiance autod√©clar√©e en Python) : La perception de soi par l'√©tudiant est souvent corr√©l√©e √† la performance r√©elle.

weeks_in_course (semaines dans le cours) : Une plus longue dur√©e d'engagement peut entra√Æner une meilleure compr√©hension.

projects_completed (projets compl√©t√©s) : L'application pratique des comp√©tences via des projets est tr√®s pertinente.

Conclusion tir√©e de l'Importance des Variables
L'analyse de ces importances aide √† confirmer les hypoth√®ses sur les facteurs qui contribuent le plus √† la r√©ussite. Elle est essentielle pour le Machine Learning car elle fournit des insights m√©tiers pr√©cieux, permettant par exemple de concentrer les efforts p√©dagogiques sur les activit√©s les plus impactantes.


# 7 : ANALYSE APPROFONDIE : √âvaluation des R√©sultats (L'Heure de V√©rit√©) 

Interpr√©tation des Statistiques Descriptives et de l'Analyse Pr√©liminaire
1. Statistiques Descriptives pour les Colonnes Num√©riques (df.describe())
Ce tableau fournit un r√©sum√© de la tendance centrale (moyenne), de la dispersion (√©cart-type) et de la forme de la distribution de chaque colonne num√©rique. Les observations cl√©s incluent :

student_id : Simple identifiant. Ses statistiques ne sont pas directement interpr√©tables pour l'analyse.

age (√¢ge) : La moyenne, l'√©cart-type (std) et la plage d'√¢ges (minimum, maximum, quartiles) aident √† comprendre le profil d√©mographique des √©tudiants.

weeks_in_course (semaines dans le cours) : Donne un aper√ßu de la dur√©e typique d'engagement des √©tudiants (moyenne, engagement le plus court et le plus long).

hours_spent_learning_per_week (heures d'√©tude par semaine) : R√©v√®le l'effort hebdomadaire moyen des √©tudiants et sa variabilit√©. C'est une caract√©ristique cruciale pour la performance.

practice_problems_solved, projects_completed, tutorial_videos_watched : Ces m√©triques quantifient l'engagement et l'effort. Leurs moyennes et √©carts-types montrent les niveaux d'activit√© typiques.

debugging_sessions_per_week (sessions de d√©bogage par semaine) : Indique la fr√©quence √† laquelle les √©tudiants rencontrent et r√©solvent des probl√®mes, refl√©tant potentiellement des d√©fis d'apprentissage ou une approche proactive.

self_reported_confidence_python (confiance autod√©clar√©e en Python) : Cette auto-√©valuation fournit une mesure subjective qui peut √™tre corr√©l√©e avec la performance r√©elle.

final_exam_score (score d'examen final) : C'est la variable cible pour la r√©gression. Sa moyenne, son √©cart-type et ses quartiles montrent la performance globale des √©tudiants.

passed_exam (r√©ussite de l'examen) : C'est la variable cible binaire (0 ou 1). Sa moyenne donne la proportion d'√©tudiants ayant r√©ussi l'examen (par exemple, si la moyenne est de 0,3, alors 30 % ont r√©ussi).

√Ä partir de ces statistiques, vous pouvez d√©duire si les donn√©es sont asym√©triques, s'il existe des valeurs aberrantes potentielles, et obtenir une id√©e g√©n√©rale du profil et de la performance de l'√©tudiant typique.

2. Informations sur le DataFrame (df.info())
Cet affichage fournit un r√©sum√© concis du DataFrame :

RangeIndex : Confirme le nombre d'observations (3000 dans votre cas).

Data columns : Liste toutes les colonnes (24 au total).

Non-Null Count : Montre que toutes les colonnes ont 3000 entr√©es non-nulles, ce qui indique que les valeurs manquantes ont √©t√© g√©r√©es avec succ√®s (apr√®s les √©tapes de SimpleImputer et d'encodage).

Dtype : Sp√©cifie le type de donn√©es pour chaque colonne (par exemple, int64, float64). Ceci est crucial pour garantir que les caract√©ristiques sont correctement trait√©es par les mod√®les de Machine Learning.

memory usage : Fournit une estimation de la consommation de m√©moire du DataFrame.

3. Visualisation des Distributions de Quelques Caract√©ristiques Cl√©s
Les histogrammes pour des variables comme l'√¢ge, les semaines de cours, les heures d'√©tude par semaine, et le score final offrent des aper√ßus visuels :

Forme des Distributions : Vous pouvez voir si les variables sont distribu√©es normalement, asym√©triques (par exemple, asym√©trie √† droite pour la variable "semaines dans le cours" si de nombreux √©tudiants terminent le cours rapidement), ou pr√©sentent plusieurs pics.

Valeurs Aberrantes (Outliers) : Des valeurs extr√™mement √©lev√©es ou faibles peuvent appara√Ætre comme des barres isol√©es aux extr√©mit√©s des histogrammes.

Concentration des Donn√©es : O√π se situent la majorit√© des points de donn√©es pour chaque variable (par exemple, de nombreux √©tudiants pourraient √™tre concentr√©s dans certaines tranches d'√¢ge ou d'heures d'√©tude).

4. Visualisation des Fr√©quences pour l'Exp√©rience de Programmation Ant√©rieure
Le diagramme de comptage (countplot) pour prior_programming_experience montre la distribution des √©tudiants selon leurs niveaux d'exp√©rience de programmation (par exemple, D√©butant, Interm√©diaire, Avanc√©). Cela aide √† comprendre l'arri√®re-plan d'exp√©rience de votre population √©tudiante, ce qui peut √™tre un pr√©dicteur significatif de la performance √† l'examen.


# Conclusion G√©n√©rale 

Conclusion G√©n√©rale de l'Analyse
Ce projet d√©montre une ma√Ætrise compl√®te du cycle de vie de la Data Science, en appliquant des mod√®les d'apprentissage automatique √† des enjeux vari√©s : la pr√©diction acad√©mique et l'aide au diagnostic m√©dical.

Phase Pr√©liminaire et Pr√©paration : L'analyse a √©t√© fond√©e sur une phase rigoureuse de statistique descriptive et d'EDA, qui a confirm√© les hypoth√®ses m√©tier (la corr√©lation entre l'engagement et la performance) et permis de construire un pipeline de nettoyage et de preprocessing (imputation, encodage) essentiel √† la fiabilit√© des mod√®les.

Mod√©lisation et R√©sultats (R√©gression) : Le Random Forest Regressor a permis d'expliquer 60 % de la variance des scores d'examen (R2=0,60). Bien que l'erreur moyenne de 9 points (MAE) laisse une marge d'am√©lioration, le mod√®le a rempli son r√¥le principal : l'analyse d'Importance des Variables a valid√© que les efforts pratiques sont les facteurs les plus critiques, fournissant des insights pour orienter la p√©dagogie.

Analyse Critique (Classification) : L'√©tude sur le diagnostic a mis en lumi√®re l'enjeu fondamental du Machine Learning en environnement critique : la n√©cessit√© d'adapter l'√©valuation. La Matrice de Confusion a servi √† souligner que le co√ªt de l'Erreur de Type II (Faux N√©gatif) est maximal, justifiant la priorit√© accord√©e √† la m√©trique de Rappel (Sensibilit√©) plut√¥t qu'√† la pr√©cision globale.

En d√©finitive, ce projet confirme ma capacit√© √† non seulement construire des mod√®les pr√©dictifs robustes, mais surtout √† interpr√©ter les r√©sultats et les m√©triques en fonction des cons√©quences concr√®tes dans les domaines de l'√©ducation et de la sant√©.
